## Writeup

### Overview

This challenge is related with one of the popular fields in unstructured data these days - approximate nearest neighbor search. The challenge is to understand a basic Faiss example and input the correct query results.

Background: I was very familiar with Faiss as a former open source developer at [Milvus](https://milvus.io), a vector database powered by Faiss. I did multiple optimizations on Faiss and its algorithms. If you are interested in Faiss, feel free to read [this article](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) by Facebook engineers.

Note: You do NOT need any prior experience with Faiss to solve this challenge. The challenge is designed to be easy to understand and solve.

### Analysis

We are provided with a `challenge` binary which is written in C++. Let's take a brief look at the decompiled code. I assume reader already has some basic, high level understanding of Faiss. For example, what is a vector, what is vector similarity search, what is the *index* in Faiss, etc.

#### Part 1

```cpp
v4 = time(0LL);
srand(v4);
v5 = std::operator<<<std::char_traits<char>>(&std::cout, "[+] Adding vectors to the database...");
std::ostream::operator<<(v5, &std::endl<char,std::char_traits<char>>);
v27 = (float *)operator new[](0x30D4000uLL);

for ( i = 0; i <= 99999; ++i )
{
    for ( j = 0; j <= 127; ++j )
    {
        get_rand();
        LODWORD(v27[128 * i + j]) = _mm_cvtsi128_si32(v3);
    }
    v3 = 0LL;
    *(double *)v3.m128i_i64 = (double)i / 1000.0 + v27[128 * i];
    *(float *)v3.m128i_i32 = *(double *)v3.m128i_i64;
    v27[128 * i] = *(float *)v3.m128i_i32;
}

faiss::IndexFlatL2::IndexFlatL2((faiss::IndexFlatL2 *)v31, 128LL);
faiss::IndexIVFFlat::IndexIVFFlat(v32, v31, 128LL, 100LL, 1LL);
faiss::IndexIVF::train((faiss::IndexIVF *)v32, 100000LL, v27);
faiss::IndexIVF::add((faiss::IndexIVF *)v32, 100000LL, v27);
v6 = std::operator<<<std::char_traits<char>>(&std::cout, "[!] Vectors added to the database.");
```

In the first part, as the logs hinted, we are adding vectors to the database. At the start, `srand(0)` is called to initialize the rng. It is not really "random" since we know the timestamp when the binary is run. Then, 100000 vectors are generated and added to the database. The vectors are generated by calling `get_rand()`. The `get_rand()` function is implemented as follows, which is simply getting a random float from 0 to 1. Notice `*(double *)v3.m128i_i64 = (double)i / 1000.0 + v27[128 * i]` which means the first element of each vector has some number added to it.

```cpp
float get_rand(void)
{
    return (float)rand() / 2147483600.0;
}
```

Then, a number of calls to Faiss library are made. The first call is to create a `faiss::IndexFlatL2` object. If we read the doc or tutorial, we will notice it is a *quantizer* for the index. Then we create a `faiss::IndexIVFFlat` object which is the index. Checking this [tutorial](https://github.com/facebookresearch/faiss/blob/0b74765cca3090c9b01336ee70233d18e7f5effc/tutorial/cpp/2-IVFFlat.cpp) on `IVFFLAT`, we can see they are very similar in structure. 

Parameters to IVFFLAT: `d = 128` is the dimension of the vectors, `nlist = 100` is the number of clusters in IVF's K-NN training. The last parameter, `1LL`, refers to [metric type: L2](https://github.com/facebookresearch/faiss/blob/0b74765cca3090c9b01336ee70233d18e7f5effc/faiss/MetricType.h#LL22C5-L22C5), a.k.a Euclidean distance.

Finally, `train` and `add` are called.

#### Part 2

```cpp
v7 = std::operator<<<std::char_traits<char>>(&std::cout, "[+] Querying...");
std::ostream::operator<<(v7, &std::endl<char,std::char_traits<char>>);
v28 = (void *)operator new[](0x1400uLL);

for ( k = 0; k <= 9; ++k )
{
    for ( l = 0; l <= 127; ++l )
    {
        *(float *)v3.m128i_i32 = get_rand();
        *((_DWORD *)v28 + 128 * k + l) = _mm_cvtsi128_si32(v3);
    }
    v3 = 0LL;
    *(double *)v3.m128i_i64 = (double)k / 1000.0 + *((float *)v28 + 128 * k);
    *(float *)v3.m128i_i32 = *(double *)v3.m128i_i64;
    *((_DWORD *)v28 + 128 * k) = v3.m128i_i32[0];
}

v29 = (void *)operator new[](0xF0uLL);
v30 = (void *)operator new[](0x78uLL);
faiss::IndexIVF::search(v32, 10LL, v28, 3LL, v30, v29, 0LL);

for ( ii = 0; ii <= 9; ++ii )
{
    v8 = std::operator<<<std::char_traits<char>>(&std::cout, "Query ");
    v9 = std::ostream::operator<<(v8, (unsigned int)(ii + 1));
    v10 = std::operator<<<std::char_traits<char>>(v9, " - nearest neighbour indices:");
    std::ostream::operator<<(v10, &std::endl<char,std::char_traits<char>>);
    std::operator<<<std::char_traits<char>>(&std::cout, "> ");
    v11 = std::istream::operator>>(&std::cin, &v24);
    v12 = std::istream::operator>>(v11, &v25);
    std::istream::operator>>(v12, &v26);
    if ( *((_QWORD *)v29 + 3 * ii) != v24
        || *((_QWORD *)v29 + 3 * ii + 1) != v25
        || *((_QWORD *)v29 + 3 * ii + 2) != v26 )
    {
        v13 = std::operator<<<std::char_traits<char>>(&std::cout, "[!] Wrong! Exiting...");
        std::ostream::operator<<(v13, &std::endl<char,std::char_traits<char>>);
        v14 = 1;
        goto LABEL_35;
    }
}
```

Firstly, 10 query vectors are generated in the exact same way as base vectors. Next, `faiss::IndexIVF::search` is called. The parameters, `n = 10` is the number of queries, and `k = 3` is the number of nearest neighbours to return. 2 arrays are returned, the first one is the indices of the nearest neighbours `v29`, and the second one is the distances to the nearest neighbours `v30`.

Finally, we are asked to input the indices of the nearest neighbours. Inputting all 10x3 indices correctly will give us the flag.

### Solution

As long as you understand what the code is performing, it would be easy to solve the challenge. Below is the plan:

1. Connect to the server, record the timestamp.
2. Use Faiss' Python API to generate the exact same base vectors as the server locally. Train and add the vectors to the database.
3. Similarly, generate the exact same query vectors. Search the database with query vectors.

Faiss already gave examples of Python API usage, and a Dockerfile on setting up all dependencies. Notice that Faiss 1.7.3 is used, which can be indicated from the shared library `libfaiss.so`. We can then reimplement the binary in Python to solve this challenge.

Due to the property of "approximate" nearest neighbour search, the results may not be exactly the same. Therefore you might get flag after a few failures.